{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Droplets - software for reproducible and collaborative research \u00ef\u0192 This initiative compiles a series of tutorials describing tools and good practices to make your research analysis more organized, automatic and reproducible with an astrophysical science case as a guiding thread. We understand that people will learn a tool only when they need it or they see the value on using it. Therefore, the tutorials follow the narrative of presenting tools after a scientific necessity appears, such as the necessity to share your work with colleagues or when you need to manage the dependencies of some software you need. Following this philosophy, instead of presenting a complex system to organize full reproducibily at once, we will be progressively incorporating new approaches as they respond to new necessities we encounter. The topics covered here are: Jupyter: the XXI century lab book Collaborative science with git Software management with conda Python visualization and ipython widgets Share your results with the world with Binder Reproducible workflows to rule them all: Snakemake Contairenization for the posterit Your work for the posterity. Zenodo This documentation and all the resources used in the course are available in the github repository droplets The authors \u00ef\u0192 Javier Mold\u00f3n, Sebasti\u00e1n Luna and Laura Darriba, from the Institute of Astrophysics of Andalusia (IAA-CSIC), a Severo Ochoa Center . We are open to contributions from anyone! Visit the Github repository Droplets . Credits \u00ef\u0192 This content is based on our own experience and on excellent open-source online material. We want to mention specially: NBIS Reproducible research course The Turing Way Home image: More Water Droplets on spider web. (2017, November 28). Wikimedia Commons, the free media repository. Image License \u00ef\u0192 MIT (see LICENSE.txt in the Droplets Github repository).","title":"Home"},{"location":"#droplets-software-for-reproducible-and-collaborative-research","text":"This initiative compiles a series of tutorials describing tools and good practices to make your research analysis more organized, automatic and reproducible with an astrophysical science case as a guiding thread. We understand that people will learn a tool only when they need it or they see the value on using it. Therefore, the tutorials follow the narrative of presenting tools after a scientific necessity appears, such as the necessity to share your work with colleagues or when you need to manage the dependencies of some software you need. Following this philosophy, instead of presenting a complex system to organize full reproducibily at once, we will be progressively incorporating new approaches as they respond to new necessities we encounter. The topics covered here are: Jupyter: the XXI century lab book Collaborative science with git Software management with conda Python visualization and ipython widgets Share your results with the world with Binder Reproducible workflows to rule them all: Snakemake Contairenization for the posterit Your work for the posterity. Zenodo This documentation and all the resources used in the course are available in the github repository droplets","title":"Droplets - software for reproducible and collaborative research"},{"location":"#the-authors","text":"Javier Mold\u00f3n, Sebasti\u00e1n Luna and Laura Darriba, from the Institute of Astrophysics of Andalusia (IAA-CSIC), a Severo Ochoa Center . We are open to contributions from anyone! Visit the Github repository Droplets .","title":"The authors"},{"location":"#credits","text":"This content is based on our own experience and on excellent open-source online material. We want to mention specially: NBIS Reproducible research course The Turing Way Home image: More Water Droplets on spider web. (2017, November 28). Wikimedia Commons, the free media repository. Image","title":"Credits"},{"location":"#license","text":"MIT (see LICENSE.txt in the Droplets Github repository).","title":"License"},{"location":"about/","text":"Nam erat ut tu Phrygiisque omnia regnum \u00ef\u0192 Section level 1 \u00ef\u0192 Lorem markdownum erat capillos primus solent. Et nescio refert concentu Section level 2 \u00ef\u0192 Lorem markdownum erat capillos primus solent. Et nescio refert concentu Section level 3 \u00ef\u0192 Lorem markdownum erat capillos primus solent. Et nescio refert concentu Section level 4 \u00ef\u0192 Lorem markdownum erat capillos primus solent. Et nescio refert concentu Telamon aversa, suis est nate, dira habenas arcuerat illa exspatiantur natas bello non concubitusque. Ipsa conplexibus crescere casus Tonantis, Vasta usque anima avertere ebur deos , ora. Moenia falcata Priapi si licet, in calido, hic est conposuit honoratas et acuta una! Ipse constitit domum veneno rates, avibus convicti laevaque ausa sed poni Scythiam spe est hortus; alis. Canem Panchaia utque canos Sallentinumque licet; virgineo viderat pectora , nostra, retexi. Una illud summa , ne figuras inmensos excedam domus, terga tuque! Exactus superare alis ministeriis aetas infectaque quid; quo ferarum? Aeris tibi femineusque tegit, iam fossae nostros Fortuna de parentes nulla et etiam es. Flebile lacrimas quoque, et, huic ullus et pronus umquam, laniata coniunctaque erat. Nec te oculos gravitate agros centum Delphice. Et iterum tempora antiquam frangitur ferarum cetera Omni aequor Famae in fugit inmoriuntur ille vulnus Vivum modo sunt pacta percussa agitata Repulsae nescia et feroxque Non vestros tamen intellegit vestigia amato erat Triplices me inter illic nervo aquis amavit \u00ef\u0192 Demittitur donec, Pico a dextra maduere quem paulatim Acrisio? Requiescit ipsum. Radicis neque iunctisque manu contigit latuit. Generatus plumbo visaque cantato flammas fulvo cauda et ordine atque? Induroque est; sinu tenebant, si vox sanguine pedes mugitus et arcu inquit communicat frigus tectum. utf = dvr(token) + encryption.url(tweetCopyPci); if (read_lcd >= networkLaptop) { modelPanelSpeakers.rpc_sku_system = namespace_dslam_horse + maximize + videoAluPrint; express += pc; } else { text_wiki.cardCd = 3; } ftp(28 - bloatware + power_bridge_word, 22, alpha_access); Inmanibus mollirique tenues dubiaque vitam et habeant iter fluctus huius satam illis cecidere venerisque arguit solus hunc sede albentia. Procorum ipsa, terreat, est indignantesque reddere. Bos saepe timentes? Dentes ora! Inponit stetit urbesque inponis, arces citra dixit et gaudere amor ambrosiam unius et pocula erectus, calescit auferat. Quot partes ora ut mea est tempora silva sua usque, ego quem? Sinistro ardor, et, in erat Arne bis Pandion! Quamvis illa tabellis rumpit hoc ira securum! Sunt tamen colitur tergoque aut, effetus moras, est anno: remotos ripas, velocibus discede referam pinguntur. Est iunxit infans ambarum quantum vocis tam humus splendidior: rutilos ametur pars tamen modo lignum nisi?","title":"Nam erat ut tu Phrygiisque omnia regnum"},{"location":"about/#nam-erat-ut-tu-phrygiisque-omnia-regnum","text":"","title":"Nam erat ut tu Phrygiisque omnia regnum"},{"location":"about/#section-level-1","text":"Lorem markdownum erat capillos primus solent. Et nescio refert concentu","title":"Section level 1"},{"location":"about/#section-level-2","text":"Lorem markdownum erat capillos primus solent. Et nescio refert concentu","title":"Section level 2"},{"location":"about/#section-level-3","text":"Lorem markdownum erat capillos primus solent. Et nescio refert concentu","title":"Section level 3"},{"location":"about/#section-level-4","text":"Lorem markdownum erat capillos primus solent. Et nescio refert concentu Telamon aversa, suis est nate, dira habenas arcuerat illa exspatiantur natas bello non concubitusque. Ipsa conplexibus crescere casus Tonantis, Vasta usque anima avertere ebur deos , ora. Moenia falcata Priapi si licet, in calido, hic est conposuit honoratas et acuta una! Ipse constitit domum veneno rates, avibus convicti laevaque ausa sed poni Scythiam spe est hortus; alis. Canem Panchaia utque canos Sallentinumque licet; virgineo viderat pectora , nostra, retexi. Una illud summa , ne figuras inmensos excedam domus, terga tuque! Exactus superare alis ministeriis aetas infectaque quid; quo ferarum? Aeris tibi femineusque tegit, iam fossae nostros Fortuna de parentes nulla et etiam es. Flebile lacrimas quoque, et, huic ullus et pronus umquam, laniata coniunctaque erat. Nec te oculos gravitate agros centum Delphice. Et iterum tempora antiquam frangitur ferarum cetera Omni aequor Famae in fugit inmoriuntur ille vulnus Vivum modo sunt pacta percussa agitata Repulsae nescia et feroxque Non vestros tamen intellegit vestigia amato erat","title":"Section level 4"},{"location":"about/#triplices-me-inter-illic-nervo-aquis-amavit","text":"Demittitur donec, Pico a dextra maduere quem paulatim Acrisio? Requiescit ipsum. Radicis neque iunctisque manu contigit latuit. Generatus plumbo visaque cantato flammas fulvo cauda et ordine atque? Induroque est; sinu tenebant, si vox sanguine pedes mugitus et arcu inquit communicat frigus tectum. utf = dvr(token) + encryption.url(tweetCopyPci); if (read_lcd >= networkLaptop) { modelPanelSpeakers.rpc_sku_system = namespace_dslam_horse + maximize + videoAluPrint; express += pc; } else { text_wiki.cardCd = 3; } ftp(28 - bloatware + power_bridge_word, 22, alpha_access); Inmanibus mollirique tenues dubiaque vitam et habeant iter fluctus huius satam illis cecidere venerisque arguit solus hunc sede albentia. Procorum ipsa, terreat, est indignantesque reddere. Bos saepe timentes? Dentes ora! Inponit stetit urbesque inponis, arces citra dixit et gaudere amor ambrosiam unius et pocula erectus, calescit auferat. Quot partes ora ut mea est tempora silva sua usque, ego quem? Sinistro ardor, et, in erat Arne bis Pandion! Quamvis illa tabellis rumpit hoc ira securum! Sunt tamen colitur tergoque aut, effetus moras, est anno: remotos ripas, velocibus discede referam pinguntur. Est iunxit infans ambarum quantum vocis tam humus splendidior: rutilos ametur pars tamen modo lignum nisi?","title":"Triplices me inter illic nervo aquis amavit"},{"location":"conda/","text":"","title":"Software management with conda"},{"location":"git/","text":"Going full version control with git \u00ef\u0192 You have received an e-mail from a good colleague. email Hey there, Thanks for sharing the notebook with your exploratory analysis, the results are really promising! I have some code of my own to compute some statistics. I attached the last version of my program in this e-mail. I think the last version compiled well (I hope) but you may need some dependencies I have in my laptop. I think we can collaborate and do a more in-depth analysis together. Please, send me your current results and I will continue from there. [need some reworking] Cheers, Galileo Starting a collaboration by sharing code and analysis by e-mail can be a mess. Most probably, a number of unconnected files, with different versions will appear, and tracking versions and stages will become more a more complicated. We need a tool that help us organize all our files, and make it simple and immediate to share exactly the same files with all your collaborators Objectives and scope .... Introduction to Git \u00ef\u0192 Git is a widely used system (both in academia and industry) for version controlling files and collaborating on code. It is used to track changes in (text) files, thereby establishing a history of all edits made to each file, together with short messages about each change and information about who made it. Git is mainly run from the command line, but there are several tools that have implemented a graphical user interface to run git commands. Using version control for tracking your files, and edits to those, is an essential step in making your computational research reproducible. A typical git workflow consists of: making distinct and related edits to one or several files committing those changes (i.e. telling git to add those edits to the history, together with a message about what those changes involve) and pushing the commit to a remote repository (i.e. syncing your local project directory with one in the cloud) There are many benefits of using git in your research project: You are automatically forced into a more organized way of working, which is usually a first step towards reproducibility. If you have made some changes to a file and realize that those were probably not a good idea after all, it is simple to view exactly what the changes were and revert them. If there is more than one person involved in the project, git makes it easy to collaborate by tracking all edits made by each person. It will also handle any potential conflicting edits. Using a cloud-based repository hosting service (the one you push your commits to), like e.g. Github or Bitbucket , adds additional features, such as being able to discuss the project, comment on edits, or report issues. At some point your project will be published. Github or Bitbucket (or similar) are excellent places to publicly distribute your code. Other researchers can then use git to access the code needed for reproducing your results, in exactly the state it was when used for the publication. If needed, you can host private repositories on Github and Bitbucket as well. This may be convenient during an ongoing research project, before it is publicly published. The best way to get an idea about git is simply to start using it. The tutorial below will guide you through the essential steps, with a focus on what is needed for making a project reproducible. There are many additional features of both git and the web-based repository hosting services (like Github and Bitbucket) that are not included here. If you are interested in learning more, the web is filled with information (see some examples below)! Tell me more \u00ef\u0192 For a more complete introduction to git, check e.g. Wikipedia A simple git guide \"Got 15 minutes and want to learn Git?\" Git reference manual Set up \u00ef\u0192 This tutorial depends on files from the course Bitbucket repo. Take a look at the intro for instructions on how to set it up if you haven't done so already. Install git \u00ef\u0192 Chances are that you already have git installed on your computer. You can check by running e.g. git --version . If you don't have git, install it following the instructions here . Configure git \u00ef\u0192 If it is the first time you use git on your computer, you may want to configure it so that it is aware of your username. This username should match the username you have registered on Bitbucket. This will make it easier when you want to sync local changes with your remote Bitbucket repository. git config --global user.name \"Mona Lisa\" Tip If you have several accounts (e.g. both a Github and Bitbucket account), and thereby several different usernames, you can configure git on a per-repository level. Change directory into the relevant local git repository and run: git config user.name \"Mona Lisa\" This will set the default username for that repository only. Create an account at Bitbucket \u00ef\u0192 If you have not done so already, go to bitbucket.org and create an account. Note You can also create an account on another online hosting service for version control, e.g. GitHub or GitLab . The exercises below are written with examples from Bitbucket, but the same thing can be done on alternative services, although the exact menu structure and link placements differ a bit. Practical exercise \u00ef\u0192 Create a new git repository \u00ef\u0192 Login to Bitbucket and press the plus button to the left and select Create repository : Make sure you are listed as the owner Add a repository name, e.g. git_tutorial You can keep the repo private or make it public, as you wish Skip including a README Make sure Git is selected for version control You will now be redirected to the repository page. It is an empty repository, so there is not much to see yet. We want to add some contents (files) to the repository. To do that we will first clone the repository locally: Open a terminal and cd to a directory where you want to clone your newly created git repository (perhaps make a new directory for this course if you haven't done so already). Attention Important: the directory should not be within the reproducible_research_course directory, since this is itself a git-tracked directory. Once you are in your directory of choice, run the following command (just make sure to change user to your Bitbucket username and git_tutorial to your repository name, in case you chose something different): git clone https://user@bitbucket.org/user/git_tutorial.git What will happen now is that the git repository will be cloned (i.e. downloaded) to your computer. You might get a warning that the repository is empty (which in fact is the case). A new directory, git_tutorial (or a different name if you choose so), has now been created, cd into that directory. This is a git version-tracked directory. How can you know? Run git status ! It will probably return something like: On branch master. Initial commit. nothing to commit (create/copy files and use \"git add\" to track). Tip If you try to run git status in a non-git directory, it will say that it is not a git repository . The way this works is that git adds a hidden directory .git/ in the root of a git tracked directory (run ls -a to see it). This hidden directory contains all information and settings git needs in order to run and version track your files. This also means that your git-tracked directory is self-contained, i.e. you can simply delete it and everything that has to do with git in connection to that directory will be gone. Remember that git told you \" nothing to commit (create/copy files and use \"git add\" to track \"? Lets do that! Copy the following files and directories from the reproducible_research_course/git directory, into your git_tutorial directory: Dockerfile Snakefile config.yml environment.yml code/ Once you have done that, run git status again. It will tell you that there are files in the directory that are not version tracked by git. Note For the purpose of this tutorial, the exact contents of the files you just copied are not important. But you will probably recognize many of them, as they are all files used in the MRSA case study . The environment.yml file contains the Conda environment with all the software used in the analysis (see the Conda tutorial ). The Snakefile and config.yml are both used to define the Snakemake workflow, that you should recognize from the Snakemake tutorial . The Dockerfile contains the recipe for making a Docker container for the analysis, this will be convered in detail in the Docker tutorial . The code/ directory contains an R Markdown report that is used in the final step of the analysis (more on this in the R Markdown tutorial ). Quick recap We have used two git commands this far: git clone - to clone a remote repository locally (e.g. from Bitbucket). This is only done the first time you want to download the repository locally. git status - this is a command you should use a lot . It will tell you, amongst other things, the status of your git clone in relation to the online remote repository. Committing \u00ef\u0192 We will now commit the untracked files. A commit is essentially a set of changes to a set of files. Preferably, the changes making out a commit should be related to something, e.g. a specific bug fix or a new feature. Our first commit will be to add the copied files to the repository. Run (as suggested by git status ): git add Dockerfile Snakefile Run git status again! See that we have added Dockerfile and Snakefile to our upcoming commit (listed under \" Changes to be committed \"). This is called the staging area, and the files there are staged to be committed. We might as well commit all files in one go! Use git add on the remaining files as well: git add config.yml environment.yml code/ Run git status and see that all files are in the staging area, and that no files are listed as untracked. We are now ready to commit! Run: git commit -m \"Add initial files\" The -m option adds a commit message. This should be a short description of what the commit contains. Tip There are some general guidelines on how to write good commit messages. The following points are often mentioned: Separate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how In the command above we just added a short subject line (\"Add initial files\"). It is capitalized, less than 50 characters, does not end with a period, and uses imperative mood (Add!). It is possible to add a descriptive body text as well, as hinted by the points above. This is easiest done in a text editor. If you run git commit without the -m flag, git will open the default terminal text editor (can be configured) where you can write a longer commit message and body. Run git status (yep, again!). It should tell you \" nothing to commit, working directory clean \". Now, let's edit a file. Open up environment.yml in your favorite editor, and change the version of bowtie2 to a different value, e.g. bowtie2=2.1 . Run git status . It will tell you that there are modifications in one file ( environment.yml ) compared to the previous commit. This is nice! We don't have to keep track of what files we have edited, git will do that for us. Run git diff environment.yml . This will show you the changes made to the file. A - means a deleted line, a + means an added line. There are also shown a few lines before and after the changes, to put them in context. Let's edit another file! Open config.yml and change the line genome_id: NCTC8325 to genome_id: ST398 . Run git status . Run git diff . If we don't specify a file, it will show all changes made in any file, compared to the previous commit. Do you see your changes? Ok, we made our changes. Let's commit them! Run: git add config.yml environment.yml This will add both our files to the staging area at the same time. Run git status and see that the changes in both config.yml and environment.yml are ready to be committed. But wait a minute! Shouldn't each commit optimally be a specified set of changes? Yes! So we want to make two commits, one for each change. Let's remove environment.yml from the staging area. git status tells us how to do this: \" (use \"git reset HEAD ...\" to unstage) \". So run: git reset HEAD environment.yml Run git status again. See that now only config.yml is staged for being committed, whereas the changes in environment.yml are tracked by git, but not ready to be commited. Commit the changes in config.yml : git commit -m \"Change to ST398 for alignment\" Add and commit the changes in environment.yml : git status git add environment.yml git status git commit -m \"Change bowtie2 version\" git status You don't have to run git status between each command, but it can be useful in the beginning while learning what each command does. To see a history of our changes so far, run: git log As you can see, each commit is a point in history. The more often you commit, and the more specific you keep your commits, the better (more fine-grained) history and version tracking you will have of your files. We can also try to delete a file: rm Dockerfile Run git status . As you can see, git tells us that the file is deleted, but that the deletion is not committed. In the same way as we commit edits to files, we need to commit a deletion of a file: git add Dockerfile git status git commit -m \"remove Dockerfile\" git status git log Here we used rm Dockerfile to delete the file and git add Dockerfile to stage the deletion. You can also use git rm Dockerfile to do both these operations in one step. Quick recap We now added four important git commands to our repertoire: git add - adds a file so that changes in that file can be committed. git rm - the opposite of git add , i.e. sets a file to be deleted in the next commit. git commit - commits the changes we have staged (by using git add or git rm ). git log - shows us the commit history. Pushing \u00ef\u0192 So far we have just worked locally. A strength with git is that we can add a remote location to push our commits to. In fact, we already have setup such a remote, since we created the repository at Bitbucket and cloned it locally. The idea is that you work and edit your files locally, and commit changes as you go along. At some points, preferably as often as possible, you push your changes to the remote. Your local copy and the remote copy are then in sync. In principle, you can now safely delete your local copy since everything is backed up in the cloud, including the full commit history. This also enables collaboration. Several users can work on their local clones of a given repository and push changes to a common remote location. Let's try this out in practice! Run git remote -v . This will show you what remote location is connected to your local git clone. The short name of the default remote is usually \" origin \". Run git branch . This will show you the name of the current branch. By default this will be \" master \". Attention We have not mentioned branches yet (it is touched on at the end) but they are a major feature of git. They allow you to have different \"versions\" of a repository. As an example, during software development it is common to have a release branch containing code that is working correctly, and a development branch containing code with new features and fixes but also potential bugs that have not been fixed yet. Once the development branch is fixed and working, it can be merged into the release branch. End-users will typically use the code in the release branch only. Now we will push the latest commits to the master branch to our remote origin: git push -u origin master Run git status . This should tell you that \" Your branch is up-to-date with 'origin/master'. \". Go to your Bitbucket repository in your browser again and click on Source to the left. You should now see that the files you have locally appear here as well! Click on config.yml . You will see the contents of the file. Notice that it is the latest version, where we changed \"genome_id\". Click on Diff, in the upper right corner. You will see the changes made to this file compared to the previous commit. Click History. You will see an overview of the commits involving changes made to this file. Click Commits, to the left in the main menu. You will see an overview of all commits made. Click on a specific commit to see the changes introduced by that commit. Click on the commit that was the initial commit, where we added all the files. You can now click on View source in the top right corner. You will now see the files as they were when we first added them. Specifically you can see that the Dockerfile is back, even though we deleted it! Click on Source to the left again to return to the latest version. Quick recap We now learned yet another important git command: git push - to push local commits to the remote repository Conflicts \u00ef\u0192 We will now learn how to manage conflicts. This is important to know, since it will probably happen sooner or later. It can get a bit tricky, but the important thing is not to panic! :) On the Bitbucket web page, click on environment.yml and click Edit. We can now edit this file directly on the web. This is generally not recommended, but we will do it here to demonstrate a point. Let's pretend that using multiqc version 1.3 did not work. Change the multiqc version to 1.4: multiqc=1.4 Click Commit. Add the commit message: \"Update multiqc version to 1.4\". Click Commit. Click Commits to the left to see the commit history, and your latest change at the top. Now we have a change in the remote repository that is not yet in our local clone. This could happen for instance if a collaborator of yours committed a change and pushed it to Bitbucket. Go back to your local terminal. Run git status . Notice that git says: \" Your branch is up-to-date with 'origin/master'. \". This is of course not true, but our local git clone is not yet aware of the remote changes. We will get those changes soon. But first, we will edit environment.yml locally as well! (It may be the case that your collaborator thought it was good to use multiqc version 1.4, whereas you thought it would be better to use multiqc version 1.2, but neither of you communicated that to the other.) Use a text editor and change the multiqc line to: multiqc=1.2 Commit your change (use git status along the way if you want to check what is happening in the different steps): git status git add environment.yml git status git commit -m \"Downgraded multiqc to v1.2\" git status Now let's try to push this commit! git push Tip Note that after the initial push you probably don't have to specify -u origin master , git will figure that out by itself. Read the error message. It should be fairly informative of what is going on. In essence it will not allow you to push since there are conflicting changes made to the remote repository. We will now download the changes made to the remote: git fetch Now run git status . Unlike before, our local git clone now is aware of the latest changes pushed to the remote. It will tell you something along the lines: \" Your branch and 'origin/master' have diverged, and have 1 and 1 different commit each, respectively. \". Now, since we ran git fetch our local git has up-to-date information about the status of the remote repository. We can therefore run the following to see what the difference is between the current state of our local clone and the master branch on the remote origin: git diff origin/master Now let's try to integrate the remote changes with our local changes and get up to sync with the remote: git pull Tip Note that you can skip the git fetch command if you want to and run git pull directly. The difference is that fetch will just update git with the latest information of the remote status, whereas pull will try to integrate and sync those changes to your local clone directly. As you have probably noticed, the git pull command resulted in a conflict. Git tells us about this and suggests that we should fix the conflicts and commit that. As always, run git status to get an overview! You will see that you have, so called, unmerged paths and that the conflicting file is environment.yml , since both modified the same line in this file. To fix a conflict, open the affected file in a text editor. You will see that it now looks something like this: channels: - conda-forge - bioconda dependencies: - fastqc=0.11.6 - sra-tools=2.8 - snakemake-minimal=5.3.0 <<<<<<< HEAD - multiqc=1.2 ======= - multiqc=1.4 >>>>>>> d9b35ef61d2fde56fcbd64aacb10a96098c67cbf - bowtie2=2.3 - samtools=1.6 - htseq=0.9 - graphviz=2.38.0 - xorg-libxrender - xorg-libxpm - r-ggplot2=3.1.1 - r-reshape2=1.4.3 - r-pheatmap=1.0.12 - bioconductor-rtracklayer=1.42.1 - bioconductor-geoquery=2.50.5 - r-rmarkdown=1.12 The part between <<<<<<< HEAD and ======= is your local version, and the part between ======= and >>>>>>> d9b35ef61d2fde56fcbd64aacb10a96098c67cbf is the one added to the remote and which caused the conflict when you tried to pull those changes to your local repository. The long sequence of characters is the commit id (the first 7 are e.g. displayed on Bitbucket under Commits) which will be different for your repository. It is now up to you to decide which version to keep, or to change it to a third alternative. Let's say that you are confident that it is better to run multiqc v1.2 rather than v1.4. Edit the file so that it looks like you want it to, i.e. remove the lines added by git and delete the line with multiqc=1.4 . The final file should look like this: channels : - conda-forge - bioconda dependencies : - fastqc=0.11.6 - sra-tools=2.8 - snakemake-minimal=5.3.0 - multiqc=1.2 - bowtie2=2.3 - samtools=1.6 - htseq=0.9 - graphviz=2.38.0 - xorg-libxrender - xorg-libxpm - r-ggplot2=3.1.1 - r-reshape2=1.4.3 - r-pheatmap=1.0.12 - bioconductor-rtracklayer=1.42.1 - bioconductor-geoquery=2.50.5 - r-rmarkdown=1.12 Run git status , notice that it says use \"git add ...\" to mark resolution ? Let's do that! git add environment.yml Run git status again! It will now tell us: \" All conflicts fixed but you are still merging. (use \"git commit\" to conclude merge) .\". So, you probably guessed it, run: git commit -m \"Merge and set multiqc to v1.2\" Finally, push these changes to Bitbucket: git push Go to Bitbucket in the browser and click Commits. You should be able to see a graph showing that the paths diverged (where one commit set the version to 1.4 and the other to 1.2) and that they are later merged, and the conflict fixed! Quick recap We now learned how to sync our local clone with the remote one on Bitbucket, and how to fix potential conflicting commits. We added these commands to our repertoire: git fetch - downloads information from the remote repository. git pull - both fetches and integrates changes from the remote repository. Ignoring files \u00ef\u0192 Git is aware of all files within the repository. However, it is not uncommon to have files that we don't want git to track. For instance, our analysis might produce several intermediate files and results. We typically don't track such files. Rather, we want to track the actual code and other related files (e.g. configuration files) that produce the intermediate and result files, given the raw input data. Let's make some mock-up intermediate and result files. These are some of the files that would have been generated by the Snakemake workflow if it was run. mkdir intermediate mkdir results touch intermediate/multiqc_general_stats.txt touch results/supplementary.pdf touch log.tmp Run git status . You will see that git tells you that you have untracked files. However, we don't want git to track these files anyway. To tell git what files to ignore we use a file called .gitignore . Let's create it: touch .gitignore Open the .gitignore file in an editor and add the following lines to it: # Ignore these directories: results/ intermediate/ # Ignore temporary files: *.tmp Run git status again. Now there is no mention of the results and intermediate directories or the log.tmp file. Notice that we can use wildcards (*) to ignore files with a given pattern, e.g. a specific extension. Go ahead and add, commit, and push the .gitignore file. Quick recap We now learned how to use a .gitignore file to control what directories and files git should ignore. Tagging \u00ef\u0192 Git allows us to tag commits. This is of particular importance when it comes to reproducible research. We can tag commits that represent important points in the history of our project. This can be, for example, the version of the repository that was used for the manuscript submission, the version used during resubmission, and, most importantly, the version used for the final publication. The first two examples are mainly useful internally, but the latter is essential for other researchers to be able to rerun your published analysis. Let's try this out! Let's assume that the status of the repository as it is now is ready for a submission to a journal. It may for example contain the scripts that were used to generate the manuscript figures. Let's add a tag: git tag \"submission1\" To push this tag to Bitbucket we use: git push --tags Go to Bitbucket and check Commits. Can you see that the tag has been added? Let's assume we now got comments from the reviewers, and by fixing those we had to update our code. Open config.yml and change the line max_reads: 25000 to max_reads: 50000 . Commit and push that change: git add config.yml git commit -m \"Increase number of reads\" git push Now let's say that the reviewers were happy and the manuscript was accepted for publication. Let's immediately add a tag: git tag \"publication\" git push --tags After the study was published you realized that you get nicer QC information if you upgrade multiqc. Open environment.yml and change multiqc=1.2 to multiqc=1.5a . Add, commit, and push this change: git add environment.yml git commit -m \"Upgrade to newer multiqc version\" git push Go to Bitbucket and click Downloads, and then Tags. Here users can download a compressed file containing the repository at the versions specified by the tags. Alternatively, git users who want to reproduce your analysis with the code used for the publication can clone the Bitbucket repository and then run git checkout publication . You can try this in your local clone, run: git checkout publication Open environment.yml and note that the multiqc version now is back to 1.2! To go back to the latest version, run: git checkout master Again, open environment.yml and see that it now has version 1.5a! Finally, you could run git log --oneline --decorate to get a condensed commit history, where you should also be able to see the tagged commits. Quick recap We now learned how to tag important commits: git tag - add a tag to a commit git checkout - update files to match the versions in the given branch or tag name Branching and merging \u00ef\u0192 A more advanced, but commonly used, feature of Git is called branching. Branching allows you to diverge from the main line of work and edit or update your code and files, e.g. to test out a new analysis or some experimental feature, without affecting your main work. If the work you did in the branch turns out to be useful you can merge that back into your main branch. On the other hand, if the work didn't turn out as planned, you can simply delete the branch and continue where you left off in your main line of work. Another use case for branching is when you are working in a project with multiple people. Branching can be a way of compartmentalizing your teams work on different parts of the project and enables merging back into the main branch in a controlled fashion. Let's start trying out branching! Recall that we can see the current branch by running: git branch This tells us that there is only the master branch at the moment. Let's make a new branch: git branch test_alignment Run git branch again to see the available branches. Do you note which one is selected as the active branch? Let's move to our newly created branch: git checkout test_alignment Tip You can create and checkout a new branch in one line with git checkout -b branch_name Let's add some changes to our new branch! We'll use this to try out a different set of parameters on the sequence alignment step of the case study project. Edit the Snakefile so that the shell command of the align_to_genome rule looks like this (add the --very-sensitive-local option): shell ( \"bowtie2 --very-sensitive-local -x \" + indexBase + \" -U {input.fastq} > {output} 2> {log}\" ) Add and commit the change! To get a visual view of your branches and commits you can use the command: git log --graph --all --oneline We can push the commits in this branch to our remote repository if we want, but one could also choose to just have it locally and then merge it into the master branch when needed. Anyway, let's push it! git push -u origin test_alignment Note The -u in the command above sets the remote (upstream) tracking to origin for our test_alignment branch. If you would have just typed git push test_alignment git would not know where to push it. However, the next time you push commits to this branch you can simply use git push without the -u since we only need to specify the remote once. Again, you can see your remote locations using git remote -v . You will see it's name (e.g. origin) and URL. Go the the repository at Bitbucket in your browser and see if the new branch has appeared. Under \"Source\" you can select which branch to view. Can you see the difference in the Snakefile depending on which branch you choose? Under \"Commits\" you should be able to see the commit history of all branches together with a graph. Make an additional edit to the Snakefile . To the same line as above, add the --trim5 5 flag: shell ( \"bowtie2 --very-sensitive-local --trim5 5 -x \" + indexBase + \" -U {input.fastq} > {output} 2> {log}\" ) Add, commit and push this change. Remember, you should be able to just use git push now. It is often useful to see what the differences exists between branches. You can use the diff command for this: git diff master --color-words This shows the difference between the active branch (test_alignment) and master. Here we add the argument --color-words which should display the difference on a word- rather than line-basis. Do you see that git reports --very-sensitive-local --trim5 5 to be the difference between the test_alignment and master branches? Now, assume that we have tested our code and the alignment analysis is run successfully with our new parameters. We want to merge our work into the master branch. It is good to start with checking the differences between branches (as we just did) so that we know what we will merge. Next, checkout the branch you want to merge into, i.e. master: git checkout master To merge, run: git merge test_alignment A default merge commit message appears. Close the terminal editor (e.g. ctrl + X if Nano or :wq, Enter if Vim). Run git log --graph --all --oneline again to see how the merge commit brings back the changes made in test_alignment to master. Note When merging it is not uncommon to encounter merge conflicts. This can happen e.g. if work has continued on the master branch that is in conflict with the test_alignment branch (in this example). Handle these conflicts in the same manner as was described above. Tip If working on different features or parts of an analysis on different branches, and at the same time maintaining a working master branch for the stable code, it is convenient to periodically merge the changes made to master into relevant branches (i.e. the opposite to what we did above). That way, you keep your experimental branches up-to-date with master and make them more easy to merge into master when time comes. If we do not want to do more work in test_alignment we can delete that branch: git branch -d test_alignment Run git log --graph --all --oneline again. Note that the commits and the graph history are still there? A branch is simply a pointer to a specific commit, and that pointer has been removed. The above command only deleted the local branch. If you want to remove the branch from the remote repository as well, run: git push origin --delete test_alignment Quick recap We have now learned how to divide our work into branches and manage those: git branch branch_name - create a new branch git checkout - update files to match the versions in the given branch or tag name git merge - to merge one branch into another","title":"Version control with git"},{"location":"git/#going-full-version-control-with-git","text":"You have received an e-mail from a good colleague. email Hey there, Thanks for sharing the notebook with your exploratory analysis, the results are really promising! I have some code of my own to compute some statistics. I attached the last version of my program in this e-mail. I think the last version compiled well (I hope) but you may need some dependencies I have in my laptop. I think we can collaborate and do a more in-depth analysis together. Please, send me your current results and I will continue from there. [need some reworking] Cheers, Galileo Starting a collaboration by sharing code and analysis by e-mail can be a mess. Most probably, a number of unconnected files, with different versions will appear, and tracking versions and stages will become more a more complicated. We need a tool that help us organize all our files, and make it simple and immediate to share exactly the same files with all your collaborators","title":"Going full version control with git"},{"location":"git/#introduction-to-git","text":"Git is a widely used system (both in academia and industry) for version controlling files and collaborating on code. It is used to track changes in (text) files, thereby establishing a history of all edits made to each file, together with short messages about each change and information about who made it. Git is mainly run from the command line, but there are several tools that have implemented a graphical user interface to run git commands. Using version control for tracking your files, and edits to those, is an essential step in making your computational research reproducible. A typical git workflow consists of: making distinct and related edits to one or several files committing those changes (i.e. telling git to add those edits to the history, together with a message about what those changes involve) and pushing the commit to a remote repository (i.e. syncing your local project directory with one in the cloud) There are many benefits of using git in your research project: You are automatically forced into a more organized way of working, which is usually a first step towards reproducibility. If you have made some changes to a file and realize that those were probably not a good idea after all, it is simple to view exactly what the changes were and revert them. If there is more than one person involved in the project, git makes it easy to collaborate by tracking all edits made by each person. It will also handle any potential conflicting edits. Using a cloud-based repository hosting service (the one you push your commits to), like e.g. Github or Bitbucket , adds additional features, such as being able to discuss the project, comment on edits, or report issues. At some point your project will be published. Github or Bitbucket (or similar) are excellent places to publicly distribute your code. Other researchers can then use git to access the code needed for reproducing your results, in exactly the state it was when used for the publication. If needed, you can host private repositories on Github and Bitbucket as well. This may be convenient during an ongoing research project, before it is publicly published. The best way to get an idea about git is simply to start using it. The tutorial below will guide you through the essential steps, with a focus on what is needed for making a project reproducible. There are many additional features of both git and the web-based repository hosting services (like Github and Bitbucket) that are not included here. If you are interested in learning more, the web is filled with information (see some examples below)!","title":"Introduction to Git"},{"location":"git/#tell-me-more","text":"For a more complete introduction to git, check e.g. Wikipedia A simple git guide \"Got 15 minutes and want to learn Git?\" Git reference manual","title":"Tell me more"},{"location":"git/#set-up","text":"This tutorial depends on files from the course Bitbucket repo. Take a look at the intro for instructions on how to set it up if you haven't done so already.","title":"Set up"},{"location":"git/#install-git","text":"Chances are that you already have git installed on your computer. You can check by running e.g. git --version . If you don't have git, install it following the instructions here .","title":"Install git"},{"location":"git/#configure-git","text":"If it is the first time you use git on your computer, you may want to configure it so that it is aware of your username. This username should match the username you have registered on Bitbucket. This will make it easier when you want to sync local changes with your remote Bitbucket repository. git config --global user.name \"Mona Lisa\" Tip If you have several accounts (e.g. both a Github and Bitbucket account), and thereby several different usernames, you can configure git on a per-repository level. Change directory into the relevant local git repository and run: git config user.name \"Mona Lisa\" This will set the default username for that repository only.","title":"Configure git"},{"location":"git/#create-an-account-at-bitbucket","text":"If you have not done so already, go to bitbucket.org and create an account. Note You can also create an account on another online hosting service for version control, e.g. GitHub or GitLab . The exercises below are written with examples from Bitbucket, but the same thing can be done on alternative services, although the exact menu structure and link placements differ a bit.","title":"Create an account at Bitbucket"},{"location":"git/#practical-exercise","text":"","title":"Practical exercise"},{"location":"git/#create-a-new-git-repository","text":"Login to Bitbucket and press the plus button to the left and select Create repository : Make sure you are listed as the owner Add a repository name, e.g. git_tutorial You can keep the repo private or make it public, as you wish Skip including a README Make sure Git is selected for version control You will now be redirected to the repository page. It is an empty repository, so there is not much to see yet. We want to add some contents (files) to the repository. To do that we will first clone the repository locally: Open a terminal and cd to a directory where you want to clone your newly created git repository (perhaps make a new directory for this course if you haven't done so already). Attention Important: the directory should not be within the reproducible_research_course directory, since this is itself a git-tracked directory. Once you are in your directory of choice, run the following command (just make sure to change user to your Bitbucket username and git_tutorial to your repository name, in case you chose something different): git clone https://user@bitbucket.org/user/git_tutorial.git What will happen now is that the git repository will be cloned (i.e. downloaded) to your computer. You might get a warning that the repository is empty (which in fact is the case). A new directory, git_tutorial (or a different name if you choose so), has now been created, cd into that directory. This is a git version-tracked directory. How can you know? Run git status ! It will probably return something like: On branch master. Initial commit. nothing to commit (create/copy files and use \"git add\" to track). Tip If you try to run git status in a non-git directory, it will say that it is not a git repository . The way this works is that git adds a hidden directory .git/ in the root of a git tracked directory (run ls -a to see it). This hidden directory contains all information and settings git needs in order to run and version track your files. This also means that your git-tracked directory is self-contained, i.e. you can simply delete it and everything that has to do with git in connection to that directory will be gone. Remember that git told you \" nothing to commit (create/copy files and use \"git add\" to track \"? Lets do that! Copy the following files and directories from the reproducible_research_course/git directory, into your git_tutorial directory: Dockerfile Snakefile config.yml environment.yml code/ Once you have done that, run git status again. It will tell you that there are files in the directory that are not version tracked by git. Note For the purpose of this tutorial, the exact contents of the files you just copied are not important. But you will probably recognize many of them, as they are all files used in the MRSA case study . The environment.yml file contains the Conda environment with all the software used in the analysis (see the Conda tutorial ). The Snakefile and config.yml are both used to define the Snakemake workflow, that you should recognize from the Snakemake tutorial . The Dockerfile contains the recipe for making a Docker container for the analysis, this will be convered in detail in the Docker tutorial . The code/ directory contains an R Markdown report that is used in the final step of the analysis (more on this in the R Markdown tutorial ). Quick recap We have used two git commands this far: git clone - to clone a remote repository locally (e.g. from Bitbucket). This is only done the first time you want to download the repository locally. git status - this is a command you should use a lot . It will tell you, amongst other things, the status of your git clone in relation to the online remote repository.","title":"Create a new git repository"},{"location":"git/#committing","text":"We will now commit the untracked files. A commit is essentially a set of changes to a set of files. Preferably, the changes making out a commit should be related to something, e.g. a specific bug fix or a new feature. Our first commit will be to add the copied files to the repository. Run (as suggested by git status ): git add Dockerfile Snakefile Run git status again! See that we have added Dockerfile and Snakefile to our upcoming commit (listed under \" Changes to be committed \"). This is called the staging area, and the files there are staged to be committed. We might as well commit all files in one go! Use git add on the remaining files as well: git add config.yml environment.yml code/ Run git status and see that all files are in the staging area, and that no files are listed as untracked. We are now ready to commit! Run: git commit -m \"Add initial files\" The -m option adds a commit message. This should be a short description of what the commit contains. Tip There are some general guidelines on how to write good commit messages. The following points are often mentioned: Separate subject from body with a blank line Limit the subject line to 50 characters Capitalize the subject line Do not end the subject line with a period Use the imperative mood in the subject line Wrap the body at 72 characters Use the body to explain what and why vs. how In the command above we just added a short subject line (\"Add initial files\"). It is capitalized, less than 50 characters, does not end with a period, and uses imperative mood (Add!). It is possible to add a descriptive body text as well, as hinted by the points above. This is easiest done in a text editor. If you run git commit without the -m flag, git will open the default terminal text editor (can be configured) where you can write a longer commit message and body. Run git status (yep, again!). It should tell you \" nothing to commit, working directory clean \". Now, let's edit a file. Open up environment.yml in your favorite editor, and change the version of bowtie2 to a different value, e.g. bowtie2=2.1 . Run git status . It will tell you that there are modifications in one file ( environment.yml ) compared to the previous commit. This is nice! We don't have to keep track of what files we have edited, git will do that for us. Run git diff environment.yml . This will show you the changes made to the file. A - means a deleted line, a + means an added line. There are also shown a few lines before and after the changes, to put them in context. Let's edit another file! Open config.yml and change the line genome_id: NCTC8325 to genome_id: ST398 . Run git status . Run git diff . If we don't specify a file, it will show all changes made in any file, compared to the previous commit. Do you see your changes? Ok, we made our changes. Let's commit them! Run: git add config.yml environment.yml This will add both our files to the staging area at the same time. Run git status and see that the changes in both config.yml and environment.yml are ready to be committed. But wait a minute! Shouldn't each commit optimally be a specified set of changes? Yes! So we want to make two commits, one for each change. Let's remove environment.yml from the staging area. git status tells us how to do this: \" (use \"git reset HEAD ...\" to unstage) \". So run: git reset HEAD environment.yml Run git status again. See that now only config.yml is staged for being committed, whereas the changes in environment.yml are tracked by git, but not ready to be commited. Commit the changes in config.yml : git commit -m \"Change to ST398 for alignment\" Add and commit the changes in environment.yml : git status git add environment.yml git status git commit -m \"Change bowtie2 version\" git status You don't have to run git status between each command, but it can be useful in the beginning while learning what each command does. To see a history of our changes so far, run: git log As you can see, each commit is a point in history. The more often you commit, and the more specific you keep your commits, the better (more fine-grained) history and version tracking you will have of your files. We can also try to delete a file: rm Dockerfile Run git status . As you can see, git tells us that the file is deleted, but that the deletion is not committed. In the same way as we commit edits to files, we need to commit a deletion of a file: git add Dockerfile git status git commit -m \"remove Dockerfile\" git status git log Here we used rm Dockerfile to delete the file and git add Dockerfile to stage the deletion. You can also use git rm Dockerfile to do both these operations in one step. Quick recap We now added four important git commands to our repertoire: git add - adds a file so that changes in that file can be committed. git rm - the opposite of git add , i.e. sets a file to be deleted in the next commit. git commit - commits the changes we have staged (by using git add or git rm ). git log - shows us the commit history.","title":"Committing"},{"location":"git/#pushing","text":"So far we have just worked locally. A strength with git is that we can add a remote location to push our commits to. In fact, we already have setup such a remote, since we created the repository at Bitbucket and cloned it locally. The idea is that you work and edit your files locally, and commit changes as you go along. At some points, preferably as often as possible, you push your changes to the remote. Your local copy and the remote copy are then in sync. In principle, you can now safely delete your local copy since everything is backed up in the cloud, including the full commit history. This also enables collaboration. Several users can work on their local clones of a given repository and push changes to a common remote location. Let's try this out in practice! Run git remote -v . This will show you what remote location is connected to your local git clone. The short name of the default remote is usually \" origin \". Run git branch . This will show you the name of the current branch. By default this will be \" master \". Attention We have not mentioned branches yet (it is touched on at the end) but they are a major feature of git. They allow you to have different \"versions\" of a repository. As an example, during software development it is common to have a release branch containing code that is working correctly, and a development branch containing code with new features and fixes but also potential bugs that have not been fixed yet. Once the development branch is fixed and working, it can be merged into the release branch. End-users will typically use the code in the release branch only. Now we will push the latest commits to the master branch to our remote origin: git push -u origin master Run git status . This should tell you that \" Your branch is up-to-date with 'origin/master'. \". Go to your Bitbucket repository in your browser again and click on Source to the left. You should now see that the files you have locally appear here as well! Click on config.yml . You will see the contents of the file. Notice that it is the latest version, where we changed \"genome_id\". Click on Diff, in the upper right corner. You will see the changes made to this file compared to the previous commit. Click History. You will see an overview of the commits involving changes made to this file. Click Commits, to the left in the main menu. You will see an overview of all commits made. Click on a specific commit to see the changes introduced by that commit. Click on the commit that was the initial commit, where we added all the files. You can now click on View source in the top right corner. You will now see the files as they were when we first added them. Specifically you can see that the Dockerfile is back, even though we deleted it! Click on Source to the left again to return to the latest version. Quick recap We now learned yet another important git command: git push - to push local commits to the remote repository","title":"Pushing"},{"location":"git/#conflicts","text":"We will now learn how to manage conflicts. This is important to know, since it will probably happen sooner or later. It can get a bit tricky, but the important thing is not to panic! :) On the Bitbucket web page, click on environment.yml and click Edit. We can now edit this file directly on the web. This is generally not recommended, but we will do it here to demonstrate a point. Let's pretend that using multiqc version 1.3 did not work. Change the multiqc version to 1.4: multiqc=1.4 Click Commit. Add the commit message: \"Update multiqc version to 1.4\". Click Commit. Click Commits to the left to see the commit history, and your latest change at the top. Now we have a change in the remote repository that is not yet in our local clone. This could happen for instance if a collaborator of yours committed a change and pushed it to Bitbucket. Go back to your local terminal. Run git status . Notice that git says: \" Your branch is up-to-date with 'origin/master'. \". This is of course not true, but our local git clone is not yet aware of the remote changes. We will get those changes soon. But first, we will edit environment.yml locally as well! (It may be the case that your collaborator thought it was good to use multiqc version 1.4, whereas you thought it would be better to use multiqc version 1.2, but neither of you communicated that to the other.) Use a text editor and change the multiqc line to: multiqc=1.2 Commit your change (use git status along the way if you want to check what is happening in the different steps): git status git add environment.yml git status git commit -m \"Downgraded multiqc to v1.2\" git status Now let's try to push this commit! git push Tip Note that after the initial push you probably don't have to specify -u origin master , git will figure that out by itself. Read the error message. It should be fairly informative of what is going on. In essence it will not allow you to push since there are conflicting changes made to the remote repository. We will now download the changes made to the remote: git fetch Now run git status . Unlike before, our local git clone now is aware of the latest changes pushed to the remote. It will tell you something along the lines: \" Your branch and 'origin/master' have diverged, and have 1 and 1 different commit each, respectively. \". Now, since we ran git fetch our local git has up-to-date information about the status of the remote repository. We can therefore run the following to see what the difference is between the current state of our local clone and the master branch on the remote origin: git diff origin/master Now let's try to integrate the remote changes with our local changes and get up to sync with the remote: git pull Tip Note that you can skip the git fetch command if you want to and run git pull directly. The difference is that fetch will just update git with the latest information of the remote status, whereas pull will try to integrate and sync those changes to your local clone directly. As you have probably noticed, the git pull command resulted in a conflict. Git tells us about this and suggests that we should fix the conflicts and commit that. As always, run git status to get an overview! You will see that you have, so called, unmerged paths and that the conflicting file is environment.yml , since both modified the same line in this file. To fix a conflict, open the affected file in a text editor. You will see that it now looks something like this: channels: - conda-forge - bioconda dependencies: - fastqc=0.11.6 - sra-tools=2.8 - snakemake-minimal=5.3.0 <<<<<<< HEAD - multiqc=1.2 ======= - multiqc=1.4 >>>>>>> d9b35ef61d2fde56fcbd64aacb10a96098c67cbf - bowtie2=2.3 - samtools=1.6 - htseq=0.9 - graphviz=2.38.0 - xorg-libxrender - xorg-libxpm - r-ggplot2=3.1.1 - r-reshape2=1.4.3 - r-pheatmap=1.0.12 - bioconductor-rtracklayer=1.42.1 - bioconductor-geoquery=2.50.5 - r-rmarkdown=1.12 The part between <<<<<<< HEAD and ======= is your local version, and the part between ======= and >>>>>>> d9b35ef61d2fde56fcbd64aacb10a96098c67cbf is the one added to the remote and which caused the conflict when you tried to pull those changes to your local repository. The long sequence of characters is the commit id (the first 7 are e.g. displayed on Bitbucket under Commits) which will be different for your repository. It is now up to you to decide which version to keep, or to change it to a third alternative. Let's say that you are confident that it is better to run multiqc v1.2 rather than v1.4. Edit the file so that it looks like you want it to, i.e. remove the lines added by git and delete the line with multiqc=1.4 . The final file should look like this: channels : - conda-forge - bioconda dependencies : - fastqc=0.11.6 - sra-tools=2.8 - snakemake-minimal=5.3.0 - multiqc=1.2 - bowtie2=2.3 - samtools=1.6 - htseq=0.9 - graphviz=2.38.0 - xorg-libxrender - xorg-libxpm - r-ggplot2=3.1.1 - r-reshape2=1.4.3 - r-pheatmap=1.0.12 - bioconductor-rtracklayer=1.42.1 - bioconductor-geoquery=2.50.5 - r-rmarkdown=1.12 Run git status , notice that it says use \"git add ...\" to mark resolution ? Let's do that! git add environment.yml Run git status again! It will now tell us: \" All conflicts fixed but you are still merging. (use \"git commit\" to conclude merge) .\". So, you probably guessed it, run: git commit -m \"Merge and set multiqc to v1.2\" Finally, push these changes to Bitbucket: git push Go to Bitbucket in the browser and click Commits. You should be able to see a graph showing that the paths diverged (where one commit set the version to 1.4 and the other to 1.2) and that they are later merged, and the conflict fixed! Quick recap We now learned how to sync our local clone with the remote one on Bitbucket, and how to fix potential conflicting commits. We added these commands to our repertoire: git fetch - downloads information from the remote repository. git pull - both fetches and integrates changes from the remote repository.","title":"Conflicts"},{"location":"git/#ignoring-files","text":"Git is aware of all files within the repository. However, it is not uncommon to have files that we don't want git to track. For instance, our analysis might produce several intermediate files and results. We typically don't track such files. Rather, we want to track the actual code and other related files (e.g. configuration files) that produce the intermediate and result files, given the raw input data. Let's make some mock-up intermediate and result files. These are some of the files that would have been generated by the Snakemake workflow if it was run. mkdir intermediate mkdir results touch intermediate/multiqc_general_stats.txt touch results/supplementary.pdf touch log.tmp Run git status . You will see that git tells you that you have untracked files. However, we don't want git to track these files anyway. To tell git what files to ignore we use a file called .gitignore . Let's create it: touch .gitignore Open the .gitignore file in an editor and add the following lines to it: # Ignore these directories: results/ intermediate/ # Ignore temporary files: *.tmp Run git status again. Now there is no mention of the results and intermediate directories or the log.tmp file. Notice that we can use wildcards (*) to ignore files with a given pattern, e.g. a specific extension. Go ahead and add, commit, and push the .gitignore file. Quick recap We now learned how to use a .gitignore file to control what directories and files git should ignore.","title":"Ignoring files"},{"location":"git/#tagging","text":"Git allows us to tag commits. This is of particular importance when it comes to reproducible research. We can tag commits that represent important points in the history of our project. This can be, for example, the version of the repository that was used for the manuscript submission, the version used during resubmission, and, most importantly, the version used for the final publication. The first two examples are mainly useful internally, but the latter is essential for other researchers to be able to rerun your published analysis. Let's try this out! Let's assume that the status of the repository as it is now is ready for a submission to a journal. It may for example contain the scripts that were used to generate the manuscript figures. Let's add a tag: git tag \"submission1\" To push this tag to Bitbucket we use: git push --tags Go to Bitbucket and check Commits. Can you see that the tag has been added? Let's assume we now got comments from the reviewers, and by fixing those we had to update our code. Open config.yml and change the line max_reads: 25000 to max_reads: 50000 . Commit and push that change: git add config.yml git commit -m \"Increase number of reads\" git push Now let's say that the reviewers were happy and the manuscript was accepted for publication. Let's immediately add a tag: git tag \"publication\" git push --tags After the study was published you realized that you get nicer QC information if you upgrade multiqc. Open environment.yml and change multiqc=1.2 to multiqc=1.5a . Add, commit, and push this change: git add environment.yml git commit -m \"Upgrade to newer multiqc version\" git push Go to Bitbucket and click Downloads, and then Tags. Here users can download a compressed file containing the repository at the versions specified by the tags. Alternatively, git users who want to reproduce your analysis with the code used for the publication can clone the Bitbucket repository and then run git checkout publication . You can try this in your local clone, run: git checkout publication Open environment.yml and note that the multiqc version now is back to 1.2! To go back to the latest version, run: git checkout master Again, open environment.yml and see that it now has version 1.5a! Finally, you could run git log --oneline --decorate to get a condensed commit history, where you should also be able to see the tagged commits. Quick recap We now learned how to tag important commits: git tag - add a tag to a commit git checkout - update files to match the versions in the given branch or tag name","title":"Tagging"},{"location":"git/#branching-and-merging","text":"A more advanced, but commonly used, feature of Git is called branching. Branching allows you to diverge from the main line of work and edit or update your code and files, e.g. to test out a new analysis or some experimental feature, without affecting your main work. If the work you did in the branch turns out to be useful you can merge that back into your main branch. On the other hand, if the work didn't turn out as planned, you can simply delete the branch and continue where you left off in your main line of work. Another use case for branching is when you are working in a project with multiple people. Branching can be a way of compartmentalizing your teams work on different parts of the project and enables merging back into the main branch in a controlled fashion. Let's start trying out branching! Recall that we can see the current branch by running: git branch This tells us that there is only the master branch at the moment. Let's make a new branch: git branch test_alignment Run git branch again to see the available branches. Do you note which one is selected as the active branch? Let's move to our newly created branch: git checkout test_alignment Tip You can create and checkout a new branch in one line with git checkout -b branch_name Let's add some changes to our new branch! We'll use this to try out a different set of parameters on the sequence alignment step of the case study project. Edit the Snakefile so that the shell command of the align_to_genome rule looks like this (add the --very-sensitive-local option): shell ( \"bowtie2 --very-sensitive-local -x \" + indexBase + \" -U {input.fastq} > {output} 2> {log}\" ) Add and commit the change! To get a visual view of your branches and commits you can use the command: git log --graph --all --oneline We can push the commits in this branch to our remote repository if we want, but one could also choose to just have it locally and then merge it into the master branch when needed. Anyway, let's push it! git push -u origin test_alignment Note The -u in the command above sets the remote (upstream) tracking to origin for our test_alignment branch. If you would have just typed git push test_alignment git would not know where to push it. However, the next time you push commits to this branch you can simply use git push without the -u since we only need to specify the remote once. Again, you can see your remote locations using git remote -v . You will see it's name (e.g. origin) and URL. Go the the repository at Bitbucket in your browser and see if the new branch has appeared. Under \"Source\" you can select which branch to view. Can you see the difference in the Snakefile depending on which branch you choose? Under \"Commits\" you should be able to see the commit history of all branches together with a graph. Make an additional edit to the Snakefile . To the same line as above, add the --trim5 5 flag: shell ( \"bowtie2 --very-sensitive-local --trim5 5 -x \" + indexBase + \" -U {input.fastq} > {output} 2> {log}\" ) Add, commit and push this change. Remember, you should be able to just use git push now. It is often useful to see what the differences exists between branches. You can use the diff command for this: git diff master --color-words This shows the difference between the active branch (test_alignment) and master. Here we add the argument --color-words which should display the difference on a word- rather than line-basis. Do you see that git reports --very-sensitive-local --trim5 5 to be the difference between the test_alignment and master branches? Now, assume that we have tested our code and the alignment analysis is run successfully with our new parameters. We want to merge our work into the master branch. It is good to start with checking the differences between branches (as we just did) so that we know what we will merge. Next, checkout the branch you want to merge into, i.e. master: git checkout master To merge, run: git merge test_alignment A default merge commit message appears. Close the terminal editor (e.g. ctrl + X if Nano or :wq, Enter if Vim). Run git log --graph --all --oneline again to see how the merge commit brings back the changes made in test_alignment to master. Note When merging it is not uncommon to encounter merge conflicts. This can happen e.g. if work has continued on the master branch that is in conflict with the test_alignment branch (in this example). Handle these conflicts in the same manner as was described above. Tip If working on different features or parts of an analysis on different branches, and at the same time maintaining a working master branch for the stable code, it is convenient to periodically merge the changes made to master into relevant branches (i.e. the opposite to what we did above). That way, you keep your experimental branches up-to-date with master and make them more easy to merge into master when time comes. If we do not want to do more work in test_alignment we can delete that branch: git branch -d test_alignment Run git log --graph --all --oneline again. Note that the commits and the graph history are still there? A branch is simply a pointer to a specific commit, and that pointer has been removed. The above command only deleted the local branch. If you want to remove the branch from the remote repository as well, run: git push origin --delete test_alignment Quick recap We have now learned how to divide our work into branches and manage those: git branch branch_name - create a new branch git checkout - update files to match the versions in the given branch or tag name git merge - to merge one branch into another","title":"Branching and merging"},{"location":"github/","text":"Taking your research online \u00ef\u0192 You have received an e-mail from a good colleague. email Hi again! Thanks a lot for sending me the notebook you prepared, but actually I cannot open it. How can I do that? Also, I will be travelling during the following days, if you could send me something I can explore from my mobile phone, that would be great! Cheers, Galileo We need to compile all our results and send them in a format that helps understanding the process and the results of our analysis. One common approach is to describe all the details in the body of the e-mail and send different figures as attachments. This is a poor approach that complicate visualization, makes it difficult to connect description and figures, and that probably will miss details on how the results were obtained. Alternatively we can generate a document with the content that we can then convert to pdf so it is easy to send and be opened by anyone. However, using a Jupyter notebook has several advantatges: It is easy to export as pdf or html, and can be visualized in nearly any platform. It naturally contains the results and the logic followed to obtain them, as already seen in the previous chapter It is immediate to generate them if an update is needed. It explicitly show the full process used at each step. Objectives and scope In this section we will show how to use Github to share results with the community or your colleagues. You will be able to share code, text documents, figures or notebooks, which can be rendered automatically. How Github works \u00ef\u0192 Code, history, issues \u00ef\u0192 ... ... Why this is useful \u00ef\u0192 origin Developing your project or analysis collaboratively on GitHub or GitLab provides a prompter to document your work in detail and it provides a great opportunity to get additional contributors to your idea. Contributions can be everything from new ideas, to bug reports and actual code contributions. README and project communication \u00ef\u0192 origin README files are the welcome mat for your project. They are the first thing new visitors to your project will see and thus are part of a set of really important documents to make potential contributors feel welcome and invite them to get involved. Your README file should cover: What you are doing, for who, and why. What makes your project special and exciting. How to get started. Where to find key resources.","title":"Collaborative science online: Github"},{"location":"github/#taking-your-research-online","text":"You have received an e-mail from a good colleague. email Hi again! Thanks a lot for sending me the notebook you prepared, but actually I cannot open it. How can I do that? Also, I will be travelling during the following days, if you could send me something I can explore from my mobile phone, that would be great! Cheers, Galileo We need to compile all our results and send them in a format that helps understanding the process and the results of our analysis. One common approach is to describe all the details in the body of the e-mail and send different figures as attachments. This is a poor approach that complicate visualization, makes it difficult to connect description and figures, and that probably will miss details on how the results were obtained. Alternatively we can generate a document with the content that we can then convert to pdf so it is easy to send and be opened by anyone. However, using a Jupyter notebook has several advantatges: It is easy to export as pdf or html, and can be visualized in nearly any platform. It naturally contains the results and the logic followed to obtain them, as already seen in the previous chapter It is immediate to generate them if an update is needed. It explicitly show the full process used at each step.","title":"Taking your research online"},{"location":"github/#how-github-works","text":"","title":"How Github works"},{"location":"github/#code-history-issues","text":"... ...","title":"Code, history, issues"},{"location":"github/#why-this-is-useful","text":"origin Developing your project or analysis collaboratively on GitHub or GitLab provides a prompter to document your work in detail and it provides a great opportunity to get additional contributors to your idea. Contributions can be everything from new ideas, to bug reports and actual code contributions.","title":"Why this is useful"},{"location":"github/#readme-and-project-communication","text":"origin README files are the welcome mat for your project. They are the first thing new visitors to your project will see and thus are part of a set of really important documents to make potential contributors feel welcome and invite them to get involved. Your README file should cover: What you are doing, for who, and why. What makes your project special and exciting. How to get started. Where to find key resources.","title":"README and project communication"},{"location":"jupyter/","text":"The XXI century lab book \u00ef\u0192 You have received an e-mail from a good colleague. email Hi! The other day my friend Ptolemy told me about a \"nebulous mass in the breast of Cancer\". I observed it with my new telescope and I could resolve about 40 individual stars! This is amazing, and it could be a good topic for a paper. If you have time, please see if you can find anything interesting in this region. R.A. 130.025 deg Dec. 19.9833 deg Best regards, Galileo You think it would be a good idea to explore the stellar population on this area. Because you are not sure what to expect you would like to try different approaches, so you decide to start a Jupyter notebook and explore a star catalog around those coordinates... Objectives and scope In this section we will see the value of Jupyter notebooks as a dynamic tool for exploratory analysis. We will learn how to initialize and navigate through notebooks, the basic structure and syntax to use a Jupyter notebook, the notebook cells and the Magic commands. As an example, we will do an exploratory analysis of a star population from the Gaia catalog. Introduction to Jupyter notebooks \u00ef\u0192 The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain code, equations, visualizations and text. The functionality is partly overlapping with R Markdown (see the tutorial ), in that they both use markdown and code chunks to generate reports that integrate results of computations with the code that generated them. Jupyter Notebook comes from the Python community while R Markdown was developed by RStudio, but you could use most common programming languages in either alternative. In practice though, it's quite common that R developers use Jupyter but probably not very common that Python developers use RStudio. What are Jupyter notebooks for? \u00ef\u0192 An excellent question! Some applications could be: Python is lacking a really good IDE for doing exploratory scientific data analysis, like RStudio or Matlab. Some people use it simply as an alternative for that. The community around Jupyter notebooks is large and dynamic, and there are tons of tools for sharing, displaying or interacting with notebooks. An early ambition with Jupyter notebooks, and its predecessor IPython notebooks, was to be analogous to the lab notebook used in a wet lab. It would allow the data scientist to document her day-to-day work and interweave results, ideas, and hypotheses with the code. From a reproducibility perspective, this is one of the main advantages. Jupyter notebooks can be used, just as R Markdown, to provide a tighter connection between your data and your results by integrating results of computations with the code that generated them. They can also do this in an interactive way that makes them very appealing for sharing with others. As always, the best way is to try it out yourself and decide what to use it for! Tell me more \u00ef\u0192 The Jupyter project site contains a lot of information and inspiration. The Jupyter Notebook documentation . A guide to using widgets for creating interactive notebooks. A note on nomenclature Jupyter: a project to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages. Lives at jupyter.org . Jupyter Notebook: A web application that you use for creating and managing notebooks. One of the outputs of the Jupyter project. Jupyter Lab: A web application that you use for creating and managing notebooks. One of the outputs of the Jupyter project. Jupyter notebook: The actual .ipynb file that constitutes your notebook. Set up \u00ef\u0192 This tutorial depends on files from the course Bitbucket repo. Take a look at the intro for instructions on how to set it up if you haven't done so already. Then open up a terminal and go to reproducible_research_course/jupyter . Install Jupyter Notebook \u00ef\u0192 If you have done the Conda tutorial you should know how to define an environment and install packages using Conda. Create an environment containing the following packages from the conda-forge channel. Don't forget to activate the environment. jupyter : for running everything nb_conda : for integrating Conda with Jupyter Notebook matplotlib , ipywidgets , mpld3 , and seaborn : for generating plots pandas : for working with data frames and generating tables Attention If you are doing these exercises through a Docker container you also need the run the following: mkdir -p -m 700 /root/.jupyter/ && \\ echo \"c.NotebookApp.ip = '0.0.0.0'\" >> /root/.jupyter/jupyter_notebook_config.py Practical exercise \u00ef\u0192 The Jupyter Notebook dashboard \u00ef\u0192 One thing that sets Jupyter Notebook apart from what you might be used to is that it's a web application, i.e. you edit and run your code from your browser. But first you have to start the Jupyter Notebook server. $ jupyter notebook --allow-root [I 18:02:26.722 NotebookApp] Serving notebooks from local directory: /Users/arasmus/Documents/projects/reproducible_research_course/jupyter [I 18:02:26.723 NotebookApp] 0 active kernels [I 18:02:26.723 NotebookApp] The Jupyter Notebook is running at: [I 18:02:26.723 NotebookApp] http://localhost:8888/?token=e03f10ccb40efc3c6154358593c410a139b76acf2cae785c [I 18:02:26.723 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). [C 18:02:26.724 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=e03f10ccb40efc3c6154358593c410a139b76acf2cae785c [I 18:02:27.209 NotebookApp] Accepting one-time-token-authenticated connection from ::1 Jupyter Notebook probably opened up a web browser for you automatically, otherwise go to the address specified in the message in the terminal. Note that the server is running locally (as http://localhost:8888 ) so this does not require that you have an active internet connection. Also note that it says: Serving notebooks from local directory: /Users/arasmus/Documents/projects/reproducible_research_course/jupyter. Everything you do in your Notebook session will be stored in this directory, so you won't lose any work if you shut down the server. What you're looking at is the Notebook dashboard. This is where you manage your files, notebooks, and kernels. The Files tab shows the files in your directory. If you've done the other tutorials the file names should look familiar; they are the files needed for running the RNA-seq workflow in Snakemake. The Running tab keeps track of all your processes. The third tab, Clusters, is used for parallel computing and won't be discussed further in this tutorial. The Conda tab lets us control our Conda environments. Let's take a quick look at that. You can see that I'm currently in the jupyter_exercise environment. Let's start by creating an empty notebook by selecting the Files tab and clicking New > Notebook > Python [conda env:jupyter_exercise]. This will open up a new tab or window looking like this: Tip If you want to start Jupyter Notebooks on a cluster that you SSH to you have to do some port forwarding: ssh me@rackham.uppmax.uu.se -L8888:localhost:8888 jupyter notebook --ip 0 .0.0.0 --no-browser The very basics \u00ef\u0192 Jupyter notebooks are made up out of cells, and you are currently standing in the first cell in your notebook. The fact that it has a green border indicates that it's in \"Edit mode\", so you can write stuff in it. A blue border indicates \"Command mode\" (see below). Cells in Jupyter notebooks can be of two types: markdown or code. Markdown - These cells contain static material such as captions, text, lists, images and so on. You express this using Markdown, which is a lightweight markup language. Markdown documents can then be converted to other formats for viewing (the document you're reading now is written in Markdown and then converted to HTML). The format is discussed a little more in detail in the R Markdown tutorial . Jupyter Notebook uses a dialect of Markdown called Github Flavored Markdown, which is described here . Code - These are the cells that actually do something, just as code chunks do in R Markdown. You can write code in dozens of languages and all do all kinds of clever tricks. You then run the code cell and any output the code generates, such as text or figures, will be displayed beneath the cell. We will get back to this in much more detail, but for now it's enough to understand that code cells are for executing code that is interpreted by a kernel (in this case the Python version in your Conda environment). Before we continue, here are some shortcuts that can be useful. Note that they are only applicable when in command mode (blue frames). Most of them are also available from the menus. These shortcuts are also available from the Help menu in your notebook (there's even an option there to edit shortcuts). Enter : enter Edit mode Esc : enter Command mode Ctrl + Enter : run the cell Shift + Enter : run the cell and select the cell below Alt + Enter : run the cell and insert a new cell below Ctrl + S : save the notebook Tab : for code completion or indentation m/y: toggle between Markdown and Code cells d-d: delete a cell a/b: insert cells above/below current cell x/c/v: cut/copy/paste cells o: toggle output of current cell Some Markdown basics \u00ef\u0192 Let's use our first cell to create a header. Change the format from Code to Markdown in the drop-down list above the cell. Double click on the cell to enter editing mode (green frame) and input \"# My notebook\" (\"#\" is used in Markdown for header 1). Run the cell with Shift-Enter. Tada! Markdown is a simple way to structure your notebook into sections with descriptive notes, lists, links, images etc. Below are some examples of what you can do in markdown. Paste all or parts of it into one or more cells in your notebook to see how it renders. Make sure you set the cell type to Markdown. ## Introduction In this notebook I will try out some of the **fantastic** concepts of Jupyter Notebooks. ## Markdown basics Examples of text attributes are: * *italics* * **bold** * `monospace` Sections can be separated by horizontal lines. --- Blockquotes can be added, for instance to insert a Monty Python quote: Spam! Spam! Spam! Spam! See [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) for more information. Writing code \u00ef\u0192 Now let's write some code! Since we chose a Python kernel, Python would be the native language to run in a cell. Enter this code in the second cell and run it: print ( \"Hello world!\" ) Note how the output is displayed below the cell. This interactive way of working is one of the things that sets Jupyter Notebook apart from RStudio and R Markdown. R Markdown is typically rendered top-to-bottom in one run, while you work in a Jupyter notebook in a different way. This has partly changed with newer versions of RStudio, but it's probably still how most people use the two tools. Another indication of this is that there is no (good) way to hide the code cells if you want to render your Jupyter notebook to a cleaner looking report (for a publication for example). What is a Jupyter notebook? Let's look a little at the notebook we're currently working in. Jupyter Notebook saves it every minute or so, so you will already have it available. We can be a little meta and do this from within the notebook itself. We do it by running some shell commands in the third code cell instead of Python code. This very handy functionality is possible by prepending the command with ! . Try !ls to list the files in the current directory. Aha, we have a new file called Untitled.ipynb ! This is our notebook. Look at the first ten lines of the file by using !head Untitled.ipynb . Seems like it's just a plain old JSON file. Since it's a text file it's suitable for version control with for example Git. It turns out that Github and Jupyter notebooks are the best of friends, as we will see more of later. This switching between languages and whatever-works mentality is very prominent within the Jupyter notebook community. Variables defined in cells become variables in the global namespace. You can therefore share information between cells. Try to define a function or variable in one cell and use it in the next. For example: def print_me ( str ): print ( str ) and print_me ( \"Hi!\" ) Your notebook should now look something like this. The focus here is not on how to write Markdown or Python; you can make really pretty notebooks with Markdown and you can code whatever you want with Python. Rather, we will focus on the Jupyter Notebook features that allow you to do a little more than that. Quick recap In this section we've learned: That a Jupyter notebook consists of a series of cells, and that they can be either markdown or code cells. That we execute the code in a code cell with the kernel that we chose when opening the notebook. We can run shell commands by prepending them with ! . A Jupyter notebook is simply a text file in JSON format. Magics \u00ef\u0192 Magics constitute a simple command language that significantly extends the power of Jupyter notebooks. There are two types of magics: Line magics - Commands that are prepended by \"%\", and whose arguments only extend to the end of the line. Cell magics - Commands that start with %% and then applies to the whole cell. Must be written on the first line of a cell. Now list all available magics with %lsmagic (which itself is a magic). You add a question mark to a magic to show the help (e.g. %lsmagic? ). Some of them act as shortcuts for commonly used shell commands ( %ls , %cp , %cat , ..). Others are useful for debugging and optimizing your code ( %timeit , %debug , %prun , ..). A very useful magic, in particular when using shell commands a lot in your work, is %%capture . This will capture the stdout/stderr of any code cell and store them in a Python object. Run %%capture? to display the help and try to understand how it works. Try it out with either some Python code, other magics or shell commands. Click to see one example %%capture output %%bash echo \"Print to stdout\" echo \"Print to stderr\" >&2 and in another cell print ( \"stdout:\" + output . stdout ) print ( \"stderr:\" + output . stderr ) The %%script magic is used for specifying a program (bash, perl, ruby, ..) with which to run the code (similar to a shebang). For some languages it's possible to use these shortcuts: %%ruby %%perl %%bash %%html %%latex %%R (here you have to first install the rpy2 extension, for example with Conda, and then load with %load_ext rpy2.ipython ) Try this out if you know any of the languages above. Otherwise you can always try to print the quadratic formula with LaTeX! \\begin{array}{*{20}c} {x = \\frac{{ - b \\pm \\sqrt {b^2 - 4ac} }}{{2a}}} & {{\\rm{when}}} & {ax^2 + bx + c = 0} \\\\ \\end{array} Python's favorite library for plotting, matplotlib, has its own magic as well: %matplotlib . Try out the code below, and you should hopefully get a pretty sine wave. % matplotlib inline import numpy as np import matplotlib.pyplot as plt x = np . linspace ( 0 , 3 * np . pi , 100 ) y = np . sin ( x ) fig = plt . figure () ax = fig . add_subplot ( 111 ) line , = plt . plot ( x , y , 'r-' ) fig . canvas . draw () By default rendering is done as rasterized images which can make the quality poor. To render in scalable vector graphics format add the following line magic % config InlineBackend . figure_format = 'svg' Try it by adding it to the cell with the lineplot and run it again. Tip The %matplotlib inline and %config InlineBackend.figure_format = 'svg' line magics are only required once per notebook. You could for instance add them to the first cell where you import matplotlib for plotting. Tip You can capture the output of some magics directly like this: my_dir = % pwd print ( my_dir ) Exploring results from the MRSA workflow in a Jupyter notebook \u00ef\u0192 As you might remember from the intro , we are attempting to understand how lytic bacteriophages can be used as a future therapy for the multiresistant bacteria MRSA (methicillin-resistant Staphylococcus aureus ). We have already defined the project environment in the Conda tutorial and set up the workflow in the Snakemake tutorial . Here we explore the results from a the snakemake workflow in a Jupyter notebook as an example of how you can document your day-to-day work as a dry lab scientist. We will first create a report similar to the one in the R Markdown tutorial then generate and visualize read coverage across samples for the S. aureus genome. Update the current environment \u00ef\u0192 First update your current jupyter conda environment using the environment.yml file: Attention Run the conda update command below in your terminal (not in the notebook) with the jupyter exercise environment active. conda env update -f environment.yml Open a new notebook \u00ef\u0192 If you look at the Jupyter dashboard in your browser there should be a notebook called mrsa_notebook.ipynb . Now open the notebook with File > Open. Tip Using what you've learned about markdown in notebooks, add headers and descriptive text to subdivide sections as you add them. This will help you train how to structure and keep note of your work with a notebook. You will see that the notebook contains only two cells: one with some import statements and one with two function definitions. We'll come back to those later. Now, run the cells and add a new empty cell to the notebook. Typically the snakemake workflow will be executed from a terminal but let's try to actually run the workflow directly from within the Jupyter notebook. In the current directory you'll find the necessary Snakefile and config.yml to run the workflow. In an empty cell in your notebook, add code to run the workflow then run the cell. ......","title":"Jupyter notebooks"},{"location":"jupyter/#the-xxi-century-lab-book","text":"You have received an e-mail from a good colleague. email Hi! The other day my friend Ptolemy told me about a \"nebulous mass in the breast of Cancer\". I observed it with my new telescope and I could resolve about 40 individual stars! This is amazing, and it could be a good topic for a paper. If you have time, please see if you can find anything interesting in this region. R.A. 130.025 deg Dec. 19.9833 deg Best regards, Galileo You think it would be a good idea to explore the stellar population on this area. Because you are not sure what to expect you would like to try different approaches, so you decide to start a Jupyter notebook and explore a star catalog around those coordinates...","title":"The XXI century lab book"},{"location":"jupyter/#introduction-to-jupyter-notebooks","text":"The Jupyter Notebook is an open-source web application that allows you to create and share documents that contain code, equations, visualizations and text. The functionality is partly overlapping with R Markdown (see the tutorial ), in that they both use markdown and code chunks to generate reports that integrate results of computations with the code that generated them. Jupyter Notebook comes from the Python community while R Markdown was developed by RStudio, but you could use most common programming languages in either alternative. In practice though, it's quite common that R developers use Jupyter but probably not very common that Python developers use RStudio.","title":"Introduction to Jupyter notebooks"},{"location":"jupyter/#what-are-jupyter-notebooks-for","text":"An excellent question! Some applications could be: Python is lacking a really good IDE for doing exploratory scientific data analysis, like RStudio or Matlab. Some people use it simply as an alternative for that. The community around Jupyter notebooks is large and dynamic, and there are tons of tools for sharing, displaying or interacting with notebooks. An early ambition with Jupyter notebooks, and its predecessor IPython notebooks, was to be analogous to the lab notebook used in a wet lab. It would allow the data scientist to document her day-to-day work and interweave results, ideas, and hypotheses with the code. From a reproducibility perspective, this is one of the main advantages. Jupyter notebooks can be used, just as R Markdown, to provide a tighter connection between your data and your results by integrating results of computations with the code that generated them. They can also do this in an interactive way that makes them very appealing for sharing with others. As always, the best way is to try it out yourself and decide what to use it for!","title":"What are Jupyter notebooks for?"},{"location":"jupyter/#tell-me-more","text":"The Jupyter project site contains a lot of information and inspiration. The Jupyter Notebook documentation . A guide to using widgets for creating interactive notebooks. A note on nomenclature Jupyter: a project to develop open-source software, open-standards, and services for interactive computing across dozens of programming languages. Lives at jupyter.org . Jupyter Notebook: A web application that you use for creating and managing notebooks. One of the outputs of the Jupyter project. Jupyter Lab: A web application that you use for creating and managing notebooks. One of the outputs of the Jupyter project. Jupyter notebook: The actual .ipynb file that constitutes your notebook.","title":"Tell me more"},{"location":"jupyter/#set-up","text":"This tutorial depends on files from the course Bitbucket repo. Take a look at the intro for instructions on how to set it up if you haven't done so already. Then open up a terminal and go to reproducible_research_course/jupyter .","title":"Set up"},{"location":"jupyter/#install-jupyter-notebook","text":"If you have done the Conda tutorial you should know how to define an environment and install packages using Conda. Create an environment containing the following packages from the conda-forge channel. Don't forget to activate the environment. jupyter : for running everything nb_conda : for integrating Conda with Jupyter Notebook matplotlib , ipywidgets , mpld3 , and seaborn : for generating plots pandas : for working with data frames and generating tables Attention If you are doing these exercises through a Docker container you also need the run the following: mkdir -p -m 700 /root/.jupyter/ && \\ echo \"c.NotebookApp.ip = '0.0.0.0'\" >> /root/.jupyter/jupyter_notebook_config.py","title":"Install Jupyter Notebook"},{"location":"jupyter/#practical-exercise","text":"","title":"Practical exercise"},{"location":"jupyter/#the-jupyter-notebook-dashboard","text":"One thing that sets Jupyter Notebook apart from what you might be used to is that it's a web application, i.e. you edit and run your code from your browser. But first you have to start the Jupyter Notebook server. $ jupyter notebook --allow-root [I 18:02:26.722 NotebookApp] Serving notebooks from local directory: /Users/arasmus/Documents/projects/reproducible_research_course/jupyter [I 18:02:26.723 NotebookApp] 0 active kernels [I 18:02:26.723 NotebookApp] The Jupyter Notebook is running at: [I 18:02:26.723 NotebookApp] http://localhost:8888/?token=e03f10ccb40efc3c6154358593c410a139b76acf2cae785c [I 18:02:26.723 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation). [C 18:02:26.724 NotebookApp] Copy/paste this URL into your browser when you connect for the first time, to login with a token: http://localhost:8888/?token=e03f10ccb40efc3c6154358593c410a139b76acf2cae785c [I 18:02:27.209 NotebookApp] Accepting one-time-token-authenticated connection from ::1 Jupyter Notebook probably opened up a web browser for you automatically, otherwise go to the address specified in the message in the terminal. Note that the server is running locally (as http://localhost:8888 ) so this does not require that you have an active internet connection. Also note that it says: Serving notebooks from local directory: /Users/arasmus/Documents/projects/reproducible_research_course/jupyter. Everything you do in your Notebook session will be stored in this directory, so you won't lose any work if you shut down the server. What you're looking at is the Notebook dashboard. This is where you manage your files, notebooks, and kernels. The Files tab shows the files in your directory. If you've done the other tutorials the file names should look familiar; they are the files needed for running the RNA-seq workflow in Snakemake. The Running tab keeps track of all your processes. The third tab, Clusters, is used for parallel computing and won't be discussed further in this tutorial. The Conda tab lets us control our Conda environments. Let's take a quick look at that. You can see that I'm currently in the jupyter_exercise environment. Let's start by creating an empty notebook by selecting the Files tab and clicking New > Notebook > Python [conda env:jupyter_exercise]. This will open up a new tab or window looking like this: Tip If you want to start Jupyter Notebooks on a cluster that you SSH to you have to do some port forwarding: ssh me@rackham.uppmax.uu.se -L8888:localhost:8888 jupyter notebook --ip 0 .0.0.0 --no-browser","title":"The Jupyter Notebook dashboard"},{"location":"jupyter/#the-very-basics","text":"Jupyter notebooks are made up out of cells, and you are currently standing in the first cell in your notebook. The fact that it has a green border indicates that it's in \"Edit mode\", so you can write stuff in it. A blue border indicates \"Command mode\" (see below). Cells in Jupyter notebooks can be of two types: markdown or code. Markdown - These cells contain static material such as captions, text, lists, images and so on. You express this using Markdown, which is a lightweight markup language. Markdown documents can then be converted to other formats for viewing (the document you're reading now is written in Markdown and then converted to HTML). The format is discussed a little more in detail in the R Markdown tutorial . Jupyter Notebook uses a dialect of Markdown called Github Flavored Markdown, which is described here . Code - These are the cells that actually do something, just as code chunks do in R Markdown. You can write code in dozens of languages and all do all kinds of clever tricks. You then run the code cell and any output the code generates, such as text or figures, will be displayed beneath the cell. We will get back to this in much more detail, but for now it's enough to understand that code cells are for executing code that is interpreted by a kernel (in this case the Python version in your Conda environment). Before we continue, here are some shortcuts that can be useful. Note that they are only applicable when in command mode (blue frames). Most of them are also available from the menus. These shortcuts are also available from the Help menu in your notebook (there's even an option there to edit shortcuts). Enter : enter Edit mode Esc : enter Command mode Ctrl + Enter : run the cell Shift + Enter : run the cell and select the cell below Alt + Enter : run the cell and insert a new cell below Ctrl + S : save the notebook Tab : for code completion or indentation m/y: toggle between Markdown and Code cells d-d: delete a cell a/b: insert cells above/below current cell x/c/v: cut/copy/paste cells o: toggle output of current cell","title":"The very basics"},{"location":"jupyter/#some-markdown-basics","text":"Let's use our first cell to create a header. Change the format from Code to Markdown in the drop-down list above the cell. Double click on the cell to enter editing mode (green frame) and input \"# My notebook\" (\"#\" is used in Markdown for header 1). Run the cell with Shift-Enter. Tada! Markdown is a simple way to structure your notebook into sections with descriptive notes, lists, links, images etc. Below are some examples of what you can do in markdown. Paste all or parts of it into one or more cells in your notebook to see how it renders. Make sure you set the cell type to Markdown. ## Introduction In this notebook I will try out some of the **fantastic** concepts of Jupyter Notebooks. ## Markdown basics Examples of text attributes are: * *italics* * **bold** * `monospace` Sections can be separated by horizontal lines. --- Blockquotes can be added, for instance to insert a Monty Python quote: Spam! Spam! Spam! Spam! See [here](https://jupyter-notebook.readthedocs.io/en/stable/examples/Notebook/Working%20With%20Markdown%20Cells.html) for more information.","title":"Some Markdown basics"},{"location":"jupyter/#writing-code","text":"Now let's write some code! Since we chose a Python kernel, Python would be the native language to run in a cell. Enter this code in the second cell and run it: print ( \"Hello world!\" ) Note how the output is displayed below the cell. This interactive way of working is one of the things that sets Jupyter Notebook apart from RStudio and R Markdown. R Markdown is typically rendered top-to-bottom in one run, while you work in a Jupyter notebook in a different way. This has partly changed with newer versions of RStudio, but it's probably still how most people use the two tools. Another indication of this is that there is no (good) way to hide the code cells if you want to render your Jupyter notebook to a cleaner looking report (for a publication for example). What is a Jupyter notebook? Let's look a little at the notebook we're currently working in. Jupyter Notebook saves it every minute or so, so you will already have it available. We can be a little meta and do this from within the notebook itself. We do it by running some shell commands in the third code cell instead of Python code. This very handy functionality is possible by prepending the command with ! . Try !ls to list the files in the current directory. Aha, we have a new file called Untitled.ipynb ! This is our notebook. Look at the first ten lines of the file by using !head Untitled.ipynb . Seems like it's just a plain old JSON file. Since it's a text file it's suitable for version control with for example Git. It turns out that Github and Jupyter notebooks are the best of friends, as we will see more of later. This switching between languages and whatever-works mentality is very prominent within the Jupyter notebook community. Variables defined in cells become variables in the global namespace. You can therefore share information between cells. Try to define a function or variable in one cell and use it in the next. For example: def print_me ( str ): print ( str ) and print_me ( \"Hi!\" ) Your notebook should now look something like this. The focus here is not on how to write Markdown or Python; you can make really pretty notebooks with Markdown and you can code whatever you want with Python. Rather, we will focus on the Jupyter Notebook features that allow you to do a little more than that. Quick recap In this section we've learned: That a Jupyter notebook consists of a series of cells, and that they can be either markdown or code cells. That we execute the code in a code cell with the kernel that we chose when opening the notebook. We can run shell commands by prepending them with ! . A Jupyter notebook is simply a text file in JSON format.","title":"Writing code"},{"location":"jupyter/#magics","text":"Magics constitute a simple command language that significantly extends the power of Jupyter notebooks. There are two types of magics: Line magics - Commands that are prepended by \"%\", and whose arguments only extend to the end of the line. Cell magics - Commands that start with %% and then applies to the whole cell. Must be written on the first line of a cell. Now list all available magics with %lsmagic (which itself is a magic). You add a question mark to a magic to show the help (e.g. %lsmagic? ). Some of them act as shortcuts for commonly used shell commands ( %ls , %cp , %cat , ..). Others are useful for debugging and optimizing your code ( %timeit , %debug , %prun , ..). A very useful magic, in particular when using shell commands a lot in your work, is %%capture . This will capture the stdout/stderr of any code cell and store them in a Python object. Run %%capture? to display the help and try to understand how it works. Try it out with either some Python code, other magics or shell commands. Click to see one example %%capture output %%bash echo \"Print to stdout\" echo \"Print to stderr\" >&2 and in another cell print ( \"stdout:\" + output . stdout ) print ( \"stderr:\" + output . stderr ) The %%script magic is used for specifying a program (bash, perl, ruby, ..) with which to run the code (similar to a shebang). For some languages it's possible to use these shortcuts: %%ruby %%perl %%bash %%html %%latex %%R (here you have to first install the rpy2 extension, for example with Conda, and then load with %load_ext rpy2.ipython ) Try this out if you know any of the languages above. Otherwise you can always try to print the quadratic formula with LaTeX! \\begin{array}{*{20}c} {x = \\frac{{ - b \\pm \\sqrt {b^2 - 4ac} }}{{2a}}} & {{\\rm{when}}} & {ax^2 + bx + c = 0} \\\\ \\end{array} Python's favorite library for plotting, matplotlib, has its own magic as well: %matplotlib . Try out the code below, and you should hopefully get a pretty sine wave. % matplotlib inline import numpy as np import matplotlib.pyplot as plt x = np . linspace ( 0 , 3 * np . pi , 100 ) y = np . sin ( x ) fig = plt . figure () ax = fig . add_subplot ( 111 ) line , = plt . plot ( x , y , 'r-' ) fig . canvas . draw () By default rendering is done as rasterized images which can make the quality poor. To render in scalable vector graphics format add the following line magic % config InlineBackend . figure_format = 'svg' Try it by adding it to the cell with the lineplot and run it again. Tip The %matplotlib inline and %config InlineBackend.figure_format = 'svg' line magics are only required once per notebook. You could for instance add them to the first cell where you import matplotlib for plotting. Tip You can capture the output of some magics directly like this: my_dir = % pwd print ( my_dir )","title":"Magics"},{"location":"jupyter/#exploring-results-from-the-mrsa-workflow-in-a-jupyter-notebook","text":"As you might remember from the intro , we are attempting to understand how lytic bacteriophages can be used as a future therapy for the multiresistant bacteria MRSA (methicillin-resistant Staphylococcus aureus ). We have already defined the project environment in the Conda tutorial and set up the workflow in the Snakemake tutorial . Here we explore the results from a the snakemake workflow in a Jupyter notebook as an example of how you can document your day-to-day work as a dry lab scientist. We will first create a report similar to the one in the R Markdown tutorial then generate and visualize read coverage across samples for the S. aureus genome.","title":"Exploring results from the MRSA workflow in a Jupyter notebook"},{"location":"jupyter/#update-the-current-environment","text":"First update your current jupyter conda environment using the environment.yml file: Attention Run the conda update command below in your terminal (not in the notebook) with the jupyter exercise environment active. conda env update -f environment.yml","title":"Update the current environment"},{"location":"jupyter/#open-a-new-notebook","text":"If you look at the Jupyter dashboard in your browser there should be a notebook called mrsa_notebook.ipynb . Now open the notebook with File > Open. Tip Using what you've learned about markdown in notebooks, add headers and descriptive text to subdivide sections as you add them. This will help you train how to structure and keep note of your work with a notebook. You will see that the notebook contains only two cells: one with some import statements and one with two function definitions. We'll come back to those later. Now, run the cells and add a new empty cell to the notebook. Typically the snakemake workflow will be executed from a terminal but let's try to actually run the workflow directly from within the Jupyter notebook. In the current directory you'll find the necessary Snakefile and config.yml to run the workflow. In an empty cell in your notebook, add code to run the workflow then run the cell. ......","title":"Open a new notebook"},{"location":"quickstart/","text":"Quick start with the contents \u00ef\u0192 Each chapter will have some notes on how to install the software required to follow the examples. Here we explain how to simplify the process by having a working environment with all the dependencies with a few lines of code. Alternatively, with a single click you can just deploy a ready-to-work virtual machine with Binder. Execute on your local machine \u00ef\u0192 On Linux: \u00ef\u0192 If you don't have a conda environment on your system, this will create a temporary conda installation called my_conda_env in your current directory. This will not interfere with any installation on your system, and removing it is as simple as deleting the my_conda_env directory. More information at miniconda git clone https://github.com/spsrc/droplets.git cd droplets curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O bash ./Miniconda3-latest-Linux-x86_64.sh -b -p my_conda_env rm ./Miniconda3-latest-Linux-x86_64.sh source my_conda_env/etc/profile.d/conda.sh conda create -n droplets python = 3 .6 conda activate droplets jupyter notebook On MacOS: \u00ef\u0192 TBD Execute online (Binder) \u00ef\u0192 TBD","title":"Quick Start"},{"location":"quickstart/#quick-start-with-the-contents","text":"Each chapter will have some notes on how to install the software required to follow the examples. Here we explain how to simplify the process by having a working environment with all the dependencies with a few lines of code. Alternatively, with a single click you can just deploy a ready-to-work virtual machine with Binder.","title":"Quick start with the contents"},{"location":"quickstart/#execute-on-your-local-machine","text":"","title":"Execute on your local machine"},{"location":"quickstart/#on-linux","text":"If you don't have a conda environment on your system, this will create a temporary conda installation called my_conda_env in your current directory. This will not interfere with any installation on your system, and removing it is as simple as deleting the my_conda_env directory. More information at miniconda git clone https://github.com/spsrc/droplets.git cd droplets curl https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O bash ./Miniconda3-latest-Linux-x86_64.sh -b -p my_conda_env rm ./Miniconda3-latest-Linux-x86_64.sh source my_conda_env/etc/profile.d/conda.sh conda create -n droplets python = 3 .6 conda activate droplets jupyter notebook","title":"On Linux:"},{"location":"quickstart/#on-macos","text":"TBD","title":"On MacOS:"},{"location":"quickstart/#execute-online-binder","text":"TBD","title":"Execute online (Binder)"},{"location":"science/","text":"Starting a research project \u00ef\u0192 You have received an e-mail from a good colleague. email Hi! The other day my friend Ptolemy told me about a \"nebulous mass in the breast of Cancer\". I observed it with my new telescope and I could resolve about 40 individual stars! This is amazing, and it could be a good topic for a paper. If you have time, please see if you can find anything interesting in this region. R.A. 130.025 deg Dec. 19.9833 deg Best regards, Galileo You think it would be a good idea to explore the stellar population on this area. Because you are not sure what to expect and you want to try different approaches, you decide to start a Jupyter notebook and explore a star catalog around those coordinates... test level 1 \u00ef\u0192 ifdafk test level 2 \u00ef\u0192 lkfjadf test level 3 \u00ef\u0192 flkjdaf test level 4 \u00ef\u0192 klfjdakf test level 5 \u00ef\u0192 fadlkfjda test level 6 \u00ef\u0192 dlkfja note fadfdas type dfasfjdsa danger fdafdfsaj important fdkajsfkljda caution fdja;skfjd error fdklajsf tip fkjads;fkj warning fkdja;kfjad attention fkjdlaksf","title":"Testing"},{"location":"science/#starting-a-research-project","text":"You have received an e-mail from a good colleague. email Hi! The other day my friend Ptolemy told me about a \"nebulous mass in the breast of Cancer\". I observed it with my new telescope and I could resolve about 40 individual stars! This is amazing, and it could be a good topic for a paper. If you have time, please see if you can find anything interesting in this region. R.A. 130.025 deg Dec. 19.9833 deg Best regards, Galileo You think it would be a good idea to explore the stellar population on this area. Because you are not sure what to expect and you want to try different approaches, you decide to start a Jupyter notebook and explore a star catalog around those coordinates...","title":"Starting a research project"},{"location":"science/#test-level-1","text":"ifdafk","title":"test level 1"},{"location":"science/#test-level-2","text":"lkfjadf","title":"test level 2"},{"location":"science/#test-level-3","text":"flkjdaf","title":"test level 3"},{"location":"science/#test-level-4","text":"klfjdakf","title":"test level 4"},{"location":"science/#test-level-5","text":"fadlkfjda","title":"test level 5"},{"location":"science/#test-level-6","text":"dlkfja note fadfdas type dfasfjdsa danger fdafdfsaj important fdkajsfkljda caution fdja;skfjd error fdklajsf tip fkjads;fkj warning fkdja;kfjad attention fkjdlaksf","title":"test level 6"}]}